---
title: "chp8 concept"
author: "kwon"
date: "2018년 8월 24일"
output: html_document
---

#1
```{r}
library(ISLR)
library(tree)
boston.tree = tree(nox~., data=Boston)
plot(boston.tree)
text(boston.tree, pretty=0)

plot(nox~indus, data=Boston)
lines(x=c(0,0), y=c(0,16))
```

#2
Based on 8.2, the boosting function is:
$$f(X) = \sum_{j=1}^{p} f_j(X_j)$$

On first iteration, the boosting algorithm creates stump on one predictor, as it is stump. And to minimize the residuals, other distinct precitors will be used for creating stumps

j) a) $$\hat{f}^j(x) = \beta_{1_j} I(X_j < t_j) + \beta_{0_j}$$

j) b) $$\hat{f}(x) = \lambda\hat{f}^1(X_1) + \dots + \hat{f}^j(X_j) + \dots + \hat{f}^{p-1}(X_{p-1}) + \hat{f}^p(X_p)$$

$$f(X) = \sum_{j=1}^{p} f_j(X_j)$$

#3
```{r}
pmk = seq(0,1, 0.001)
gini = pmk*(1-pmk)*2
entropy = -(pmk*log(pmk)+(1-pmk)*log(1-pmk))
class.e = 1-pmax(pmk, 1-pmk)
matplot(pmk, cbind(gini, entropy,class.e), col=c("red", "blue", "green"))

```

#4
##a
```{r}
par(xpd=NA)
plot(NA, NA, type="n", xlim=c(-2,2), ylim=c(-3,3), xlab="X1", ylab="X2")
# X2 < 1
lines(x=c(-2,2), y=c(1,1))
# X1 < 1 with X2 < 1
lines(x=c(1,1), y=c(-3,1))
text(x=(-2+1)/2, y=-1, labels=c(-1.80))
text(x=1.5, y=-1, labels=c(0.63))
# X2 < 2 with X2 >= 1
lines(x=c(-2,2), y=c(2,2))
text(x=0, y=2.5, labels=c(2.49))
# X1 < 0 with X2<2 and X2>=1
lines(x=c(0,0), y=c(1,2))
text(x=-1, y=1.5, labels=c(-1.06))
text(x=1, y=1.5, labels=c(0.21))
```

#5
```{r}
p =c(0.1, 0.15, 0.2, 0.2, 0.55, 0.6, 0.6, 0.65, 0.7, 0.75)

# Majority apporach
sum(p>=0.5)>sum(p<0.5)
# Number of p(red|x) is greater than Number of 1-p(red|x)

# Mean appraoch
mean(p)
```


















